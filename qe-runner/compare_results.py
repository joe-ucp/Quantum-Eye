#!/usr/bin/env python
"""
Compare baseline vs adapter results generated by run_experiment.py.

Reads JSONs from /home/jovyan/persistent-volume and emits a text summary
plus optional plot into the same directory.
"""

from __future__ import annotations

import argparse
import importlib.util
import json
import os
import subprocess
import sys
from pathlib import Path
from typing import Any, Dict, Tuple

PERSISTENT = Path("/home/jovyan/persistent-volume")
MARKER = PERSISTENT / ".deps-installed.txt"
PINNED_PACKAGES = [
    "numpy==1.26.4",
    "scipy==1.11.4",
    "matplotlib==3.8.4",
    "psutil==6.0.0",
    "ffsim==0.0.63",
    "qiskit==1.3.2",
    "qiskit-aer==0.14.2",
]


def install_deps() -> None:
    marker_payload = {
        "packages": PINNED_PACKAGES,
        "extra": os.environ.get("FFSIM_PIP_EXTRA", "").strip(),
    }
    extra_parts = marker_payload["extra"].split() if marker_payload["extra"] else []

    def _deps_present() -> bool:
        try:
            for pkg in ("numpy", "scipy", "matplotlib", "psutil", "ffsim", "qiskit", "qiskit_aer"):
                if importlib.util.find_spec(pkg) is None:
                    return False
            return True
        except Exception:
            return False

    if MARKER.exists():
        try:
            recorded = json.loads(MARKER.read_text())
            if recorded == marker_payload and _deps_present():
                print("[deps] pinned deps already installed; skipping", flush=True)
                return
        except Exception:
            pass

    print("[deps] installing pinned deps for comparison...", flush=True)
    cmd = [
        sys.executable,
        "-m",
        "pip",
        "install",
        "--quiet",
        "--upgrade",
        *PINNED_PACKAGES,
        *extra_parts,
    ]
    subprocess.check_call(cmd)
    MARKER.parent.mkdir(parents=True, exist_ok=True)
    MARKER.write_text(json.dumps(marker_payload))
    print("[deps] install complete", flush=True)


def load_modules() -> None:
    import numpy as np  # type: ignore

    globals()["np"] = np


def load_results(path: Path) -> Dict[str, Any]:
    if not path.exists():
        raise FileNotFoundError(f"Missing results file: {path}")
    return json.loads(path.read_text())
def summarize_pair(
    baseline: Dict[str, Any], adapter: Dict[str, Any]
) -> Tuple[str, Dict[str, Any]]:
    metrics = [
        "energy_error",
        "best_energy_error",
        "best_energy",
        "best_iteration",
        "total_shots",
        "fidelity_to_reference",
        "wall_clock_s",
        "max_rss_mb",
        "x_accuracy",
        "y_accuracy",
        "x_correlation",
        "y_correlation",
        "qsv_score",
    ]
    lines = []
    deltas: Dict[str, Any] = {}
    lines.append("metric,baseline_mean,baseline_std,adapter_mean,adapter_std,delta(adapter-baseline)")
    for key in metrics:
        b_mean = baseline["summary"].get(key, {}).get("mean", np.nan)
        b_std = baseline["summary"].get(key, {}).get("std", np.nan)
        a_mean = adapter["summary"].get(key, {}).get("mean", np.nan)
        a_std = adapter["summary"].get(key, {}).get("std", np.nan)
        delta = a_mean - b_mean
        deltas[key] = {"delta_mean": delta, "baseline_mean": b_mean, "adapter_mean": a_mean}
        lines.append(f"{key},{b_mean:.6g},{b_std:.6g},{a_mean:.6g},{a_std:.6g},{delta:.6g}")
    return "\n".join(lines), deltas


def try_plot(baseline: Dict[str, Any], adapter: Dict[str, Any], out_path: Path) -> str:
    try:
        import matplotlib.pyplot as plt  # type: ignore
    except Exception as exc:  # pragma: no cover - plotting optional
        return f"[plot] skipped (matplotlib unavailable: {exc})"

    # Prefer plot of best energy error vs total shots; fall back to bar chart.
    b_best = baseline["summary"].get("best_energy_error", {}).get("mean", np.nan)
    a_best = adapter["summary"].get("best_energy_error", {}).get("mean", np.nan)
    b_shots = baseline["summary"].get("total_shots", {}).get("mean", np.nan)
    a_shots = adapter["summary"].get("total_shots", {}).get("mean", np.nan)

    if not np.isnan(b_best) and not np.isnan(a_best) and not np.isnan(b_shots) and not np.isnan(a_shots):
        fig, ax = plt.subplots(figsize=(5.5, 3.5))
        ax.scatter(b_shots, b_best, label="baseline", marker="o")
        ax.scatter(a_shots, a_best, label="adapter", marker="s")
        ax.set_xlabel("total shots")
        ax.set_ylabel("best energy error")
        ax.set_title("Best energy vs total shots")
        ax.legend()
        fig.tight_layout()
        fig.savefig(out_path)
        plt.close(fig)
        return f"[plot] wrote {out_path} (best energy vs shots)"

    # Fallback legacy bar plot
    metrics = ["energy_error", "wall_clock_s", "fidelity_to_reference"]
    fig, ax = plt.subplots(figsize=(6, 3.5))
    x = np.arange(len(metrics))
    width = 0.35
    b_means = [baseline["summary"].get(k, {}).get("mean", np.nan) for k in metrics]
    a_means = [adapter["summary"].get(k, {}).get("mean", np.nan) for k in metrics]
    ax.bar(x - width / 2, b_means, width, label="baseline")
    ax.bar(x + width / 2, a_means, width, label="adapter")
    ax.set_xticks(x)
    ax.set_xticklabels(metrics, rotation=15, ha="right")
    ax.set_ylabel("value")
    ax.set_title("Baseline vs Adapter")
    ax.legend()
    fig.tight_layout()
    fig.savefig(out_path)
    plt.close(fig)
    return f"[plot] wrote {out_path} (bar fallback)"


def main() -> None:
    parser = argparse.ArgumentParser(description="Compare baseline vs adapter results")
    parser.add_argument(
        "--baseline",
        type=Path,
        default=None,
        help="Path to baseline results JSON",
    )
    parser.add_argument(
        "--adapter",
        type=Path,
        default=None,
        help="Path to adapter results JSON",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=None,
        help="Path to summary text output (default: same dir as baseline)",
    )
    parser.add_argument(
        "--plot",
        type=Path,
        default=None,
        help="Path to optional plot output (default: same dir as baseline)",
    )
    args = parser.parse_args()

    install_deps()
    load_modules()

    # Set defaults: look for results in Quantum-eye-test subfolders or use provided paths
    if args.baseline is None:
        # Try to find most recent baseline in Quantum-eye-test
        quantum_eye_test = PERSISTENT / "Quantum-eye-test"
        baseline_candidates = list(quantum_eye_test.glob("*/results-baseline.json")) if quantum_eye_test.exists() else []
        if baseline_candidates:
            args.baseline = max(baseline_candidates, key=lambda p: p.stat().st_mtime)
        else:
            args.baseline = PERSISTENT / "results-baseline.json"
    
    if args.adapter is None:
        # Use same directory as baseline, look for adapter results
        adapter_candidate = args.baseline.parent / "results-adapter.json"
        if adapter_candidate.exists():
            args.adapter = adapter_candidate
        else:
            args.adapter = PERSISTENT / "results-adapter.json"
    
    # Set output paths: default to same directory as baseline
    if args.output is None:
        args.output = args.baseline.parent / "comparison_summary.txt"
    if args.plot is None:
        args.plot = args.baseline.parent / "comparison_plot.png"

    try:
        baseline = load_results(args.baseline)
        adapter = load_results(args.adapter)
    except FileNotFoundError as exc:
        print(f"[error] {exc}")
        print("Ensure both baseline and adapter results exist before comparing.")
        return

    summary_csv, deltas = summarize_pair(baseline, adapter)

    lines = []
    lines.append("=== Comparison Summary ===")
    lines.append(f"baseline file: {args.baseline}")
    lines.append(f"adapter file:  {args.adapter}")
    lines.append(f"baseline runs: {baseline.get('metadata', {}).get('runs', 'n/a')}")
    lines.append(f"adapter runs:  {adapter.get('metadata', {}).get('runs', 'n/a')}")
    if baseline.get("metadata", {}).get("runs") != adapter.get("metadata", {}).get("runs"):
        lines.append("warning: run counts differ between baseline and adapter")
    lines.append("")
    lines.append(summary_csv)
    lines.append("")
    lines.append(f"baseline seed: {baseline.get('metadata', {}).get('base_seed')}")
    lines.append(f"adapter seed:  {adapter.get('metadata', {}).get('base_seed')}")
    lines.append(f"ffsim sha (baseline): {baseline.get('metadata', {}).get('ffsim_git_sha')}")
    lines.append(f"ffsim sha (adapter):  {adapter.get('metadata', {}).get('ffsim_git_sha')}")

    args.output.write_text("\n".join(lines))
    print("\n".join(lines))

    plot_msg = try_plot(baseline, adapter, args.plot)
    print(plot_msg)

    # emit small JSON with deltas for downstream consumption
    delta_json_path = args.output.with_suffix(".json")
    delta_json_path.write_text(json.dumps({"deltas": deltas}, indent=2))
    print(f"[done] summary={args.output} delta_json={delta_json_path}")


if __name__ == "__main__":
    main()

